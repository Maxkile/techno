{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Алгоритмы интеллектуальной обработки больших объемов данных\n",
    "## Домашнее задание №3 - Дерево решений\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Общая информация**\n",
    "\n",
    "**Срок сдачи:** 25 ноября 2019, 15:00   \n",
    "**Штраф за опоздание:** -2 балла после 15:00 25 ноября, -4 балла после 15:00 2 декабря, -6 баллов после 15:00 9 декабря  -8 баллов после 15:00 16 декабря.\n",
    "\n",
    "При отправлении ДЗ указывайте фамилию в названии файла Присылать ДЗ необходимо в виде ссылки на свой github репозиторий на почту ml1.sphere@mail.ru с указанием темы в следующем формате:\n",
    "[ML0919, Задание 3] Фамилия Имя. \n",
    "\n",
    "\n",
    "Используйте данный Ipython Notebook при оформлении домашнего задания."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Задание 1 (3 балла)\n",
    "Разберитесь в коде MyDecisionTreeClassifier, который уже частично реализован. Допишите код там, где написано \"Ваш код\". Ваша реализация дерева должна работать по точности не хуже DecisionTreeClassifier из sklearn. Точность проверяется на [wine](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_wine.html) и [Speed Dating Data](https://cloud.mail.ru/public/8nHV/p6J7wY1y1)\n",
    "\n",
    "###### Задание 2 (3 балла)\n",
    "Добиться скорости работы на fit не медленнее чем в 10 раз sklearn на данных wine и Speed Dating Data. \n",
    "Для этого используем numpy.\n",
    "\n",
    "###### Задание 3 (2 балла)\n",
    "Добавьте функционал, который определяет значения feature importance. Выведите 10 главных фичей под пунктом Задание 4 (уже написано ниже) для MyDecisionTreeClassifier и DecisionTreeClassifier так, чтобы сразу были видны выводы и по MyDecisionTreeClassifier, и по DecisionTreeClassifier. Используем данные Speed Dating Data.\n",
    "\n",
    "###### Задание 4 (2 балла)\n",
    "С помощью GridSearchCV или RandomSearchCV подберите наиболее оптимальные параметры для случайного леса (Выберете 2-3 параметра). Используем данные Speed Dating Data. Задание реализуйте под пунктом Задание 5 (уже написано ниже)\n",
    "\n",
    "\n",
    "**Штрафные баллы:**\n",
    "\n",
    "1. Невыполнение PEP8 -1 балл\n",
    "2. Отсутствие фамилии в имени скрипта (скрипт должен называться по аналогии со stroykova_hw3.ipynb) -1 балл\n",
    "3. Все строчки должны быть выполнены. Нужно, чтобы output команды можно было увидеть уже в git'е. В противном случае -1 балл\n",
    "4. При оформлении ДЗ нужно пользоваться данным файлом в качестве шаблона. Не нужно удалять и видоизменять написанный код и текст. В противном случае -1 балл"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 888,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The pycodestyle_magic extension is already loaded. To reload it, use:\n",
      "  %reload_ext pycodestyle_magic\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.datasets import load_wine\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.model_selection import KFold, train_test_split, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext pycodestyle_magic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1861,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDecisionTreeClassifier:\n",
    "    NON_LEAF_TYPE = 0\n",
    "    LEAF_TYPE = 1\n",
    "\n",
    "    def __init__(self, min_samples_split=2, max_depth=None, sufficient_share=1.0, criterion='gini', max_features=None):\n",
    "        self.tree = dict()\n",
    "        self.min_samples_split = min_samples_split\n",
    "        self.max_depth = max_depth\n",
    "        self.sufficient_share = sufficient_share\n",
    "        self.num_class = -1\n",
    "        self.sufficient_share = sufficient_share\n",
    "        self.__imp_features = None#those features on which we've counted our threshold\n",
    "        if criterion == 'gini':\n",
    "            self.G_function = self.__gini#inf criteria\n",
    "        elif criterion == 'entropy':\n",
    "            self.G_function = self.__entropy\n",
    "        elif criterion == 'misclass':\n",
    "            self.G_function = self.__misclass\n",
    "        else:\n",
    "            print('invalid criterion name')\n",
    "            raise\n",
    "\n",
    "        if max_features == 'sqrt':\n",
    "            self.get_feature_ids = self.__get_feature_ids_sqrt\n",
    "        elif max_features == 'log2':\n",
    "            self.get_feature_ids = self.__get_feature_ids_log2\n",
    "        elif max_features == None:\n",
    "            self.get_feature_ids = self.__get_feature_ids_N\n",
    "        else:\n",
    "            print('invalid max_features name')\n",
    "            raise\n",
    "\n",
    "    def __gini(self, l_c, l_s, r_c, r_s):  #total gini sum(p(i)*(1 - p(i))) = 1 - sum(p(v)^2) ,l_c - left classes count,l_s - left size\n",
    "        l_s = l_s.astype('float')\n",
    "        r_s = r_s.astype('float')\n",
    "        return 1 - np.sum(((l_c / l_s) * l_c / (l_s + r_s)) + ((r_c / r_s) * r_c / (l_s + r_s)), axis=1)\n",
    "\n",
    "    def __entropy(self, l_c, l_s, r_c, r_s): #total entropy\n",
    "        return -np.sum(np.log2(l_c/l_s) * l_c/(l_s + r_s) + np.log2(r_c / r_s) * r_c / (l_s + r_s), axis=1)\n",
    "\n",
    "    def __misclass(self, l_c, l_s, r_c, r_s):#total misclass\n",
    "        return 1 - (np.max(l_c/(l_s + r_s), axis=1) + np.max(r_c / (l_s + r_s), axis=1))\n",
    "\n",
    "    def __get_feature_ids_sqrt(self, n_feature):#indexes of sqrt(n_feature) features\n",
    "        feature_ids = (range(n_feature))#python 3 does not allow to return lazy obj\n",
    "        np.random.shuffle(feature_ids)\n",
    "        return np.asarray(feature_ids[:int(np.sqrt(feature_ids.shape[0]))])\n",
    "\n",
    "    def __get_feature_ids_log2(self, n_feature):\n",
    "        feature_ids = (range(n_feature))#python 3 does not allow to return lazy obj\n",
    "        np.random.shuffle(feature_ids)\n",
    "        return np.asarray(feature_ids[:int(np.log2(feature_ids.shape[0]))])\n",
    "\n",
    "    def __get_feature_ids_N(self, n_feature):\n",
    "        return np.arange(n_feature)\n",
    "\n",
    "    def __sort_samples(self, x, y):\n",
    "        sorted_idx = x.argsort()\n",
    "        return x[sorted_idx], y[sorted_idx]\n",
    "\n",
    "    def __div_samples(self, x, y, feature_id, threshold):#div x and y onto left and right branches\n",
    "        left_mask = x[:, feature_id] > threshold\n",
    "        right_mask = ~left_mask\n",
    "        return x[left_mask], x[right_mask], y[left_mask], y[right_mask]\n",
    "    \n",
    "    def __find_threshold(self,x,y):\n",
    "        x_sorted,y_sorted = self.__sort_samples(x,y)\n",
    "        #will count mean T number between neighbour \"x\" in x_sorted and then chose one which minimizes self.G_function\n",
    "        x_unique = np.unique(x_sorted)\n",
    "        if x_unique.shape[0] == 1:#separate threshold(unique feature value) and different labels\n",
    "            thr = x_unique[0]\n",
    "            left_size = np.zeros(1)\n",
    "            right_size = y_sorted.shape[0] - left_size\n",
    "            x_indexes_right = np.where(x_sorted >= thr)#array of indexes for current threshold\n",
    "            n_classes_right = np.bincount(y_sorted[tuple(x_indexes_right)],minlength=self.num_class)    \n",
    "            n_classes_left = np.zeros(self.num_class)\n",
    "            information = self.G_function(n_classes_left,left_size.reshape(-1,1),n_classes_right,right_size.reshape(-1,1))\n",
    "               \n",
    "            return information,thr\n",
    "        else:\n",
    "            thresholds = np.asarray([(x_unique[value] + x_unique[value + 1]) / 2 for value in range(x_unique.shape[0] - 1)])\n",
    "\n",
    "        x_indexes_lr = np.asarray([(np.where(x_sorted < thr),np.where(x_sorted >= thr)) for thr in thresholds])#array of indexes for current threshold\n",
    "\n",
    "        n_classes_left = np.asarray([np.bincount(y_sorted[tuple(ind_x)],minlength=self.num_class) for ind_x in x_indexes_lr[:,0]])#number\n",
    "        n_classes_right = np.asarray([np.bincount(y_sorted[tuple(ind_x)],minlength=self.num_class) for ind_x in x_indexes_lr[:,1]])#number\n",
    "\n",
    "        left_size = np.asarray([np.sum(n_class) for n_class in n_classes_left])\n",
    "        right_size = y_sorted.shape[0] - left_size\n",
    "\n",
    "        information = self.G_function(n_classes_left,left_size.reshape(-1,1),n_classes_right,right_size.reshape(-1,1))\n",
    "        \n",
    "        ind = np.argmin(information)\n",
    "        \n",
    "        return information[ind],thresholds[ind]\n",
    "\n",
    "    #node is tuple of (node_type,feature,threshold)\n",
    "    def __fit_node(self, x, y, node_id, depth):\n",
    "        #fitting node and going to the next one\n",
    "        # stop criteria: depth,same class objects in leaf and split size > objects number\n",
    "        if (depth == self.max_depth) or (len(np.unique(y)) == 1) or (self.min_samples_split > x.shape[0]) or (np.argmax(np.bincount(y)/y.size > self.sufficient_share)):\n",
    "            #let us return any feature\n",
    "            self.tree[node_id] = (self.__class__.LEAF_TYPE, np.argmax(np.bincount(y)), np.argmax(np.bincount(y))/y.size)#simply choose class as the most common target\n",
    "            return\n",
    "        else:\n",
    "          \n",
    "            thresholds = np.asarray([self.__find_threshold(x[:, i], y) for i in self.get_feature_ids(x.shape[1])])#thresholds and features\n",
    "            feature = np.argmin(thresholds[:,0])#opt feature\n",
    "            \n",
    "            self.__imp_features[feature] += x.shape[1] * thresholds[feature,0]#Geany = sum(err_red * sample_number)\n",
    "            \n",
    "            optimal_threshold = thresholds[feature,1]\n",
    "            X_lelf, X_right, y_lelf, y_right = self.__div_samples(x, y, feature, optimal_threshold)\n",
    "            if (X_lelf.shape[0]) == 0 or (X_right.shape[0] == 0):#have no sample on left or right branches\n",
    "                self.tree[node_id] = (self.__class__.LEAF_TYPE, np.argmax(np.bincount(y)), np.argmax(np.bincount(y))/y.size)#simply choose class as the most common target\n",
    "                return\n",
    "            else:\n",
    "                \n",
    "                self.tree[node_id] = (self.__class__.NON_LEAF_TYPE, feature, optimal_threshold)\n",
    "                self.__fit_node(X_lelf, y_lelf, 2 * node_id + 1, depth + 1)#left branch\n",
    "                self.__fit_node(X_right, y_right, 2 * node_id + 2, depth + 1)#right branch\n",
    "\n",
    "\n",
    "    def fit(self, x, y):\n",
    "        if x.shape[0] != y.shape[0]:\n",
    "            raise\n",
    "        self.__imp_features = np.zeros(x.shape[1])\n",
    "        self.num_class = np.unique(y).size#number of classes\n",
    "        self.__fit_node(x, y, 0, 0)\n",
    "\n",
    "    def __predict_class(self, x, node_id):\n",
    "        node = self.tree[node_id]#create new tree node\n",
    "        if node[0] == self.__class__.NON_LEAF_TYPE:\n",
    "            _, feature_id, threshold = node\n",
    "            if x[feature_id] > threshold:\n",
    "                self.__imp_features.append(feature_id)#using this feature to count threshold\n",
    "                return self.__predict_class(x, 2 * node_id + 1)#2*node_id + 1 is just left branch\n",
    "            else:\n",
    "                return self.__predict_class(x, 2 * node_id + 2)#2*node_id + 2 is just right branch\n",
    "        else:\n",
    "            return node[1]#predicted class(node[1] is such only in leaf)\n",
    "\n",
    "    def __predict_probs(self, x, node_id):\n",
    "        node = self.tree[node_id]\n",
    "        if node[0] == self.__class__.NON_LEAF_TYPE:\n",
    "            _, feature_id, threshold = node\n",
    "            if x[feature_id] > threshold:\n",
    "                return self.__predict_probs(x, 2 * node_id + 1)\n",
    "            else:\n",
    "                return self.__predict_probs(x, 2 * node_id + 2)\n",
    "        else:\n",
    "            return node[2]#predict proba(node[2] is such only in leaf)\n",
    "        \n",
    "    def important_features(self,count):\n",
    "        if count > self.__imp_features.size:\n",
    "            return []\n",
    "        else:\n",
    "            features = np.arange(self.__imp_features.size)#features\n",
    "            indxs = self.__imp_features.argsort()\n",
    "            return features[indxs][self.__imp_features.size-count:]\n",
    "            \n",
    "    def predict(self, X):\n",
    "        return np.array([self.__predict_class(x, 0) for x in X])#starting with node 0,X - matrix of features\n",
    "\n",
    "    def predict_probs(self, X):\n",
    "        return np.array([self.__predict_probs(x, 0) for x in X])\n",
    "    \n",
    "    def fit_predict(self, x_train, y_train, predicted_x):#all at once\n",
    "        self.fit(x_train, y_train)\n",
    "        return self.predict(predicted_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1796,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 4 6 8]\n"
     ]
    }
   ],
   "source": [
    "a = np.asarray([1,2,3,4])\n",
    "print(2 * a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1863,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_clf = MyDecisionTreeClassifier(min_samples_split=2)\n",
    "clf = DecisionTreeClassifier(min_samples_split=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1864,
   "metadata": {},
   "outputs": [],
   "source": [
    "wine = load_wine()\n",
    "X_train, X_test, y_train, y_test = train_test_split(wine.data, wine.target, test_size=0.1, stratify=wine.target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Проверка скорости работы на wine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1376,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 9 ms, sys: 264 µs, total: 9.27 ms\n",
      "Wall time: 9.94 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "                       max_features=None, max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, presort=False,\n",
       "                       random_state=None, splitter='best')"
      ]
     },
     "execution_count": 1376,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1865,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 98 ms, sys: 167 µs, total: 98.1 ms\n",
      "Wall time: 98.8 ms\n"
     ]
    }
   ],
   "source": [
    "%time my_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Проверка качества работы на wine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1400,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7696969696969697"
      ]
     },
     "execution_count": 1400,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_pred=clf.predict(X_test), y_true=y_test, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1401,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8311688311688311"
      ]
     },
     "execution_count": 1401,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_pred=my_clf.predict(X_test), y_true=y_test, average='macro')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Подготовка данных Speed Dating Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1412,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/home/maxkile/Docs/Progs/git/techno-python/notebooks/hw/hw3/speed-dating-experiment/Speed Dating Data.csv', sep=',', encoding=\"ISO-8859-1\")\n",
    "#drop unnecessary\n",
    "df = df.iloc[:, :97]\n",
    "df = df.drop(['id'], axis=1)\n",
    "df = df.drop(['idg'], axis=1)\n",
    "df.drop_duplicates(subset=['iid']).gender.value_counts()\n",
    "df = df.drop(['condtn'], axis=1)\n",
    "df = df.drop(['round'], axis=1)\n",
    "df = df.drop(['position', 'positin1'], axis=1)\n",
    "df = df.drop(['order'], axis=1)\n",
    "df = df.drop(['partner'], axis=1)\n",
    "df = df.drop(['age_o', 'race_o', 'pf_o_att','pf_o_sin', 'pf_o_int','pf_o_fun', 'pf_o_amb', 'pf_o_sha','dec_o', 'attr_o', 'sinc_o', 'intel_o', 'fun_o','amb_o', 'shar_o', 'like_o', 'prob_o', 'met_o'],axis=1)\n",
    "df = df.dropna(subset=['age'])#drop null\n",
    "\n",
    "\n",
    "df.loc[:, 'tuition'] = df.loc[:, 'tuition'].str.replace(',', '').astype(np.float)\n",
    "df.loc[:, 'tuition'] = df.tuition.fillna(-999)\n",
    "df = df.dropna(subset=['imprelig', 'imprace'])\n",
    "df = df.drop(['from', 'zipcode'], axis=1)\n",
    "df.loc[:, 'income'] = df.loc[:, 'income'].str.replace(',', '').astype(np.float)\n",
    "df.loc[:, 'income'] = df.loc[:, 'income'].fillna(-999)\n",
    "df = df.dropna(subset=['date'])\n",
    "df.loc[:, 'career_c'] = df.loc[:, 'career_c'].fillna(0)\n",
    "df = df.drop(['career'], axis=1)\n",
    "df = df.drop(['sports', 'tvsports', 'exercise','dining', 'museums', 'art', 'hiking','gaming', 'clubbing', 'reading', 'tv','theater', 'movies', 'concerts','music', 'shopping', 'yoga'], axis=1)\n",
    "df = df.drop(['expnum'], axis=1)\n",
    "df.loc[:, 'field_cd'] = df.loc[:, 'field_cd'].fillna(0)\n",
    "df = df.drop(['field'], axis=1)\n",
    "pd.get_dummies(df, columns=['field_cd'],prefix='field_cd', prefix_sep='=')\n",
    "\n",
    "\n",
    "df = df.drop(['undergra'], axis=1)\n",
    "df.loc[:, 'mn_sat'] = df.loc[:, 'mn_sat'].str.replace(',', '').astype(np.float)\n",
    "df.loc[:, 'mn_sat'] = df.mn_sat.fillna(-999)\n",
    "df.loc[:, 'temp_totalsum'] = df.loc[:, ['attr1_1', 'sinc1_1', 'intel1_1','fun1_1', 'amb1_1', 'shar1_1']].sum(axis=1)\n",
    "df.loc[:, ['attr1_1', 'sinc1_1','intel1_1', 'fun1_1','amb1_1', 'shar1_1']] = (df.loc[:, ['attr1_1', 'sinc1_1','intel1_1', 'fun1_1','amb1_1', 'shar1_1']].T / df.loc[:, 'temp_totalsum'].T).T * 100\n",
    "df.loc[:, 'temp_totalsum'] = df.loc[:, ['attr2_1', 'sinc2_1','intel2_1', 'fun2_1','amb2_1', 'shar2_1']].sum(axis=1)\n",
    "df.loc[:, ['attr2_1', 'sinc2_1','intel2_1', 'fun2_1','amb2_1', 'shar2_1']] = (df.loc[:, ['attr2_1', 'sinc2_1', 'intel2_1', 'fun2_1','amb2_1', 'shar2_1']].T / df.loc[:, 'temp_totalsum'].T).T * 100\n",
    "df = df.drop(['temp_totalsum'], axis=1)\n",
    "\n",
    "\n",
    "for i in [4, 5]:\n",
    "    t_drop = ['attr{}_1'.format(i), 'sinc{}_1'.format(i),'intel{}_1'.format(i), 'fun{}_1'.format(i), 'amb{}_1'.format(i), 'shar{}_1'.format(i)]\n",
    "    if i != 4:\n",
    "        t_drop.remove('shar{}_1'.format(i))\n",
    "    df = df.drop(t_drop, axis=1)\n",
    "    \n",
    "    \n",
    "df = df.drop(['wave'], axis=1)\n",
    "df_male = df.query('gender == 1').drop_duplicates(subset=['iid', 'pid']) .drop(['gender'], axis=1) .dropna()\n",
    "df_female = df.query('gender == 0').drop_duplicates(subset=['iid']) .drop(['gender', 'match', 'int_corr', 'samerace'], axis=1) .dropna()\n",
    "df_female.columns = df_female.columns + '_f'\n",
    "df_female = df_female.drop(['pid_f'], axis=1)\n",
    "df_pair = df_male.join(df_female.set_index('iid_f'),on='pid',how='inner')\n",
    "df_pair = df_pair.drop(['iid', 'pid'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_pair.iloc[:, 1:].values\n",
    "y = df_pair.iloc[:, 0].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1866,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1)\n",
    "my_clf = MyDecisionTreeClassifier(min_samples_split=2)\n",
    "clf = DecisionTreeClassifier(min_samples_split=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Проверка скорости работы на Speed Dating Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1806,
   "metadata": {},
   "outputs": [],
   "source": [
    "# тут должен быть код типа f1_score(y_pred=clf.predict(X_test), y_true=y_test, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1868,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 74.8 ms, sys: 41 µs, total: 74.8 ms\n",
      "Wall time: 73.6 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "                       max_features=None, max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, presort=False,\n",
       "                       random_state=None, splitter='best')"
      ]
     },
     "execution_count": 1868,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time clf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1867,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/maxkile/.conda/envs/main/lib/python3.7/site-packages/ipykernel_launcher.py:36: RuntimeWarning: invalid value encountered in true_divide\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 7.16 s, sys: 3.19 ms, total: 7.17 s\n",
      "Wall time: 7.17 s\n"
     ]
    }
   ],
   "source": [
    "%time my_clf.fit(X_train,y_train)#very long..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Проверка качества работы на Speed Dating Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1794,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5584415584415584"
      ]
     },
     "execution_count": 1794,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_pred=clf.predict(X_test),y_true=y_test,average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1790,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5791272098425894"
      ]
     },
     "execution_count": 1790,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_pred=my_clf.predict(X_test),y_true=y_test,average='macro')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1871,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['field_cd', 'sinc1_1', 'fun2_1', 'fun1_1', 'amb3_1', 'imprelig_f',\n",
       "       'age', 'shar1_1', 'intel1_1_f', 'match'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 1871,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_inds = my_clf.important_features(10)\n",
    "df_pair.columns[feature_inds]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1873,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['match', 'sinc1_1', 'intel2_1_f', 'intel1_1_f', 'attr2_1', 'amb3_1',\n",
       "       'fun3_1', 'sinc3_1', 'intel2_1', 'sinc2_1'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 1873,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pair.columns[np.argsort(-clf.feature_importances_)][:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1881,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/maxkile/.conda/envs/main/lib/python3.7/site-packages/sklearn/model_selection/_split.py:1978: FutureWarning: The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 10,\n",
       " 'min_samples_leaf': 10,\n",
       " 'max_depth': 50,\n",
       " 'criterion': 'gini'}"
      ]
     },
     "execution_count": 1881,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid = {\n",
    "    'max_depth': [5, 50, 100,9],\n",
    "    'min_samples_leaf': [4, 10, 30],\n",
    "    'criterion': ['gini', 'entropy',],\n",
    "    'n_estimators': [2,6,10]\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
